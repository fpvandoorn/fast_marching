import analysis.calculus.cont_diff

open filter asymptotics
open_locale topology

/- These are the basic concepts of differentiability and asymptotics.
You can go to their definition and try to read the documentation.
It uses filters, which are explained in the topology chapter of Mathematics in Lean, and I can tell
you about them in our meeting.
Note that mathlib has two notions of derivative:
* `fderiv` stands for Fr√©chet derivative, which you can think of as the total derivative of a
  multivariate map.
* `deriv` stands for the ordinary derivative of a univariate function.
-/
#check @is_o
#check @is_O
#check @has_fderiv_at
#check @has_deriv_at
#check @differentiable_at
#check @fderiv
#check @deriv

/- Useful equivalences when working with `is_o`, and `is_O`. The last is the characterization of
  `‚àÄ·∂† x in ùìù a, p x`, which you should read as "`p(x)` holds for `x` sufficiently close to `a`". -/
#check @is_O_iff
#check @is_o_iff
#check @eventually_nhds_iff

namespace asymptotics

variables {u v f g : ‚Ñù ‚Üí ‚Ñù} {x y : ‚Ñù}

/- This is a useful lemma in mathlib, where `|¬∑|` denoted the absolute value  -/
example : | max x y | ‚â§ max (|x|) (|y|) :=
abs_max_le_max_abs_abs

/- Now prove the following variant. Find the lemma in mathlib that states that the norm of a real
number is the same as its absolute value (either use `library_search` or the mathlib documentation
search function. -/
lemma norm_max_le_max_norm_norm : ‚Äñ max x y ‚Äñ ‚â§ max (‚Äñx‚Äñ) (‚Äñy‚Äñ) :=
begin
  sorry
end

/- Prove the following lemma. This requires some basic topology, in addition to the mentioned
lemmas. -/
lemma is_o.max (hu : u =o[ùìù x] f) (hv : v =o[ùìù x] f) : (Œª x, max (u x) (v x)) =o[ùìù x] f :=
begin
  rw is_o_iff at hu hv ‚ä¢ ,
  intros y hy,
  rw eventually_nhds_iff,
  specialize hu hy,
  specialize hv hy,
  rw eventually_nhds_iff at hu hv,
  cases hu with tu pu,
  cases hv with tv pv,
  use tu‚à©tv,
  cases pv with dv jv,
  cases pu with du ju,
  cases ju with opu inu,
  cases jv with opv inv,
  split,
  intros x hx,
  specialize du x hx.1,
  specialize dv x hx.2,
  transitivity ,
  apply norm_max_le_max_norm_norm,
  apply max_le du dv,
  split,
  apply is_open.inter opu opv,
  split,
  apply inu,
  apply inv,
end

lemma my_lemma {f : ‚Ñù ‚Üí ‚Ñù} {f' : ‚Ñù} {x : ‚Ñù} :
  has_deriv_at f f' x ‚Üî (Œª (h : ‚Ñù), f (x+h) - f x - h * f') =o[ùìù 0] Œª (h : ‚Ñù), h:=
begin
  rw has_deriv_at_iff_is_o,
  rw ‚Üê map_add_left_nhds_zero x,
  rw is_o_map,
  simp [(‚àò)],

end

#check @has_deriv_at_iff_is_o
#check @has_fderiv_at_iff_is_o_nhds_zero


/- This is false: fix the statement and then proof it with `lipschitz_with_max`,
  `lipschitz_with_iff_dist_le_mul`, `prod.dist_eq`, `real.dist_eq` -/
lemma max_1_lip (a b c d :‚Ñù ) : |(max a b)-(max c d)|‚â§ max (|a-b|) (|c-d|) :=
begin
  sorry
end

#check max_1_lip


-- I think this statement is not quite right. See the next example for a corrected statement
example (u : ‚Ñù ‚Üí ‚Ñù) (x : ‚Ñù) (hu : differentiable_at ‚Ñù u x) :
  (Œª h,  max 0 (max ((u x - u (x - h)) / h) ((u x - u (x + h) / h))) - |deriv u x|)
  =o[ùìù 0] Œª h, h :=
begin
  have := my_lemma.mp hu.has_deriv_at, -- this will be useful
  have h : (Œª (h : ‚Ñù), (max ((u x - u (x - h)) / h) (u x - u (x + h) / h))- |deriv u x|  ) =o[ùìù 0] Œª (h : ‚Ñù),h,
  {rw is_o_iff,
  intros c hc,
  rw eventually_nhds_iff,
  split,
  split,
  intro y,
  rw ‚Üê max_sub_sub_right ((u x - u (x - y)) / y)  (u x - u (x + y) / y) (deriv u x),
  sorry,
  sorry,
  sorry},
  have ho :  (Œª (ho : ‚Ñù) 0) =o[ùìù 0] Œª (ho : ‚Ñù),ho,
  {}

end

example (u : ‚Ñù ‚Üí ‚Ñù) (x : ‚Ñù) (hu : differentiable_at ‚Ñù u x) :
  (Œª h,  | max (u x - u (x - h)) (u x - u (x + h)) - |h * deriv u x| |)
  =o[ùìù 0] Œª h, h :=
begin
  have := my_lemma.mp hu.has_deriv_at, -- this is how you can use `my_lemma`.
  -- apply (the corrected version of) `max_1_lip` (also using `abs_eq_max_neg`, then `is_o.max`,
  -- and then `my_lemma`, or variants of `my_lemma`.
end

end asymptotics

